{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4e9e3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ConferenceBot\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import sys \n",
    "from langchain_core.prompts import PromptTemplate,ChatPromptTemplate\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "539a3786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv,find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "groq_api_key=os.getenv('GROQ_API_KEY')\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8470421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(groq_api_key=groq_api_key,\n",
    "             model=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da096acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"Human_Segmentation.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a643d2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc3b034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "final_documents = text_splitter.split_documents(doc[:20])  # splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3820524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cffd44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ba37ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(final_documents,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "501920dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt MUST use {context} and {question} to match retriever+RunnablePassthrough below\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \n",
    "\"\"\"\n",
    "You are an advanced Research Paper Assistant designed to help students and researchers understand academic papers thoroughly. Your tasks include:\n",
    "\n",
    "1. **Summarization**\n",
    "   - Provide a concise overview of the paper’s key ideas, contributions, and main results.\n",
    "   - Use clear, accessible language while preserving technical accuracy.\n",
    "   - Highlight the research question, context, novelty, and significance.\n",
    "\n",
    "2. **Extraction**\n",
    "   - Identify and list important figures, tables, and methodology sections.\n",
    "   - For each, provide a short descriptive caption or explanation.\n",
    "\n",
    "3. **Question Answering (RAG-based)**\n",
    "   - When given a user question, search the indexed chunks of the paper.\n",
    "   - Answer directly using retrieved context, citing relevant sections.\n",
    "   - If context is insufficient, state limitations clearly.\n",
    "\n",
    "4. **Citation Notes**\n",
    "   - Generate citation-ready summaries of the paper’s contributions.\n",
    "   - Highlight datasets, methods, metrics, and limitations in brief annotated notes.\n",
    "\n",
    "---\n",
    "\n",
    "### Style & Constraints\n",
    "\n",
    "- Be precise, structured, and academic in tone.\n",
    "- Use bullet points or numbered lists for clarity.\n",
    "- Keep answers concise but informative (2–5 sentences per point).\n",
    "- Always ground answers in the paper’s text; avoid speculation.\n",
    "- When summarizing, emphasize novelty, methodology, and results.\n",
    "\n",
    "---\n",
    "\n",
    "### Example Output Structure\n",
    "\n",
    "- **Summary:** [2–3 paragraphs]\n",
    "- **Key Contributions:** [bullet list]\n",
    "- **Main Results:** [bullet list]\n",
    "- **Figures & Tables:** [list with captions]\n",
    "- **Methods:** [short excerpt or description]\n",
    "- **Citation Notes:** [annotated bullets]\n",
    "---\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2d8f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0b5b090",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "chain = (\n",
    "        {\n",
    "            \"context\": retriever,\n",
    "            \"question\": RunnablePassthrough()\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bcdd92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Explain the summary of the paper in detail.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec90d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke(\"Explain the summary of the paper in detail.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f301df7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Summary:**\n",
      "The paper discusses the comparison of various methods for human segmentation, a crucial task in computer vision. The authors compiled the computed means into comparative tables to benchmark the performance of different encoders and optimizers. They also created graphical representations, including bar plots, to visualize the trends in validation loss, training loss, validation IoU, and training IoU for all encoders and optimizers. The paper aims to provide a comprehensive analysis of the strengths and weaknesses of various approaches to human segmentation.\n",
      "\n",
      "**Key Contributions:**\n",
      "* The paper provides a thorough comparison of different encoders and optimizers for human segmentation.\n",
      "* It presents a detailed analysis of the performance of various methods using graphical representations and comparative tables.\n",
      "* The authors highlight the importance of benchmarking and evaluating the performance of different approaches to human segmentation.\n",
      "\n",
      "**Main Results:**\n",
      "* The paper presents the results of a comprehensive comparison of various encoders and optimizers for human segmentation.\n",
      "* The authors identify the strengths and weaknesses of different approaches and provide recommendations for future research.\n",
      "* The results show that the choice of encoder and optimizer has a significant impact on the performance of human segmentation models.\n",
      "\n",
      "**Figures & Tables:**\n",
      "* Bar plots comparing the average validation loss, training loss, validation IoU, and training IoU for all encoders and optimizers.\n",
      "* Comparative tables summarizing the performance of different encoders and optimizers.\n",
      "* Graphical representations of the trends in validation loss, training loss, validation IoU, and training IoU for all encoders and optimizers.\n",
      "\n",
      "**Methods:**\n",
      "The authors used a combination of computational methods and graphical representations to compare the performance of different encoders and optimizers for human segmentation. They compiled the computed means into comparative tables and created graphical representations to visualize the trends in validation loss, training loss, validation IoU, and training IoU.\n",
      "\n",
      "**Citation Notes:**\n",
      "* The paper cites various studies on human segmentation, including [11], [12], and [20].\n",
      "* The authors use datasets and methods from [8], [10], and [16] to evaluate the performance of different encoders and optimizers.\n",
      "* The paper highlights the importance of benchmarking and evaluating the performance of different approaches to human segmentation, as discussed in [18] and [19].\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516d2a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

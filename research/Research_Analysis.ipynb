{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4e9e3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys \n",
    "from langchain_core.prompts import PromptTemplate,ChatPromptTemplate\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "539a3786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv,find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "groq_api_key=os.getenv('GROQ_API_KEY')\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8470421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(groq_api_key=groq_api_key,\n",
    "             model=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da096acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"../Human_Segmentation.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a643d2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc3b034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "final_documents = text_splitter.split_documents(doc[:20])  # splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3820524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cffd44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ba37ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(final_documents,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "501920dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt MUST use {context} and {question} to match retriever+RunnablePassthrough below\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \n",
    "\"\"\"\n",
    "You are an advanced Research Paper Assistant designed to help students and researchers understand academic papers thoroughly. Your tasks include:\n",
    "\n",
    "1. **Summarization**\n",
    "   - Provide a concise overview of the paper’s key ideas, contributions, and main results.\n",
    "   - Use clear, accessible language while preserving technical accuracy.\n",
    "   - Highlight the research question, context, novelty, and significance.\n",
    "\n",
    "2. **Extraction**\n",
    "   - Identify and list important figures, tables, and methodology sections.\n",
    "   - For each, provide a short descriptive caption or explanation.\n",
    "\n",
    "3. **Question Answering (RAG-based)**\n",
    "   - When given a user question, search the indexed chunks of the paper.\n",
    "   - Answer directly using retrieved context, citing relevant sections.\n",
    "   - If context is insufficient, state limitations clearly.\n",
    "\n",
    "4. **Citation Notes**\n",
    "   - Generate citation-ready summaries of the paper’s contributions.\n",
    "   - Highlight datasets, methods, metrics, and limitations in brief annotated notes.\n",
    "\n",
    "---\n",
    "\n",
    "### Style & Constraints\n",
    "\n",
    "- Be precise, structured, and academic in tone.\n",
    "- Use bullet points or numbered lists for clarity.\n",
    "- Keep answers concise but informative (2–5 sentences per point).\n",
    "- Always ground answers in the paper’s text; avoid speculation.\n",
    "- When summarizing, emphasize novelty, methodology, and results.\n",
    "\n",
    "---\n",
    "\n",
    "### Example Output Structure\n",
    "\n",
    "- **Summary:** [2–3 paragraphs]\n",
    "- **Key Contributions:** [bullet list]\n",
    "- **Main Results:** [bullet list]\n",
    "- **Figures & Tables:** [list with captions]\n",
    "- **Methods:** [short excerpt or description]\n",
    "- **Citation Notes:** [annotated bullets]\n",
    "---\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2d8f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0b5b090",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "chain = (\n",
    "        {\n",
    "            \"context\": retriever,\n",
    "            \"question\": RunnablePassthrough()\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bcdd92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Explain the summary of the paper in detail.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec90d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke('\"Explain the summary of the paper in detail.\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f301df7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Summary:**\n",
      "The paper discusses various deep learning-based methods for semantic segmentation, particularly focusing on human segmentation. It reviews existing architectures such as U-Net, SegNet, and DeepLab, and highlights their strengths and weaknesses. The paper also explores the use of different optimizers and encoders for improving segmentation accuracy. Additionally, it mentions the importance of statistical analysis and performance evaluation of deep learning-based segmentation methods.\n",
      "\n",
      "**Key Contributions:**\n",
      "* Review of existing deep learning-based architectures for semantic segmentation\n",
      "* Discussion on the use of different optimizers and encoders for improving segmentation accuracy\n",
      "* Importance of statistical analysis and performance evaluation of deep learning-based segmentation methods\n",
      "* Comparison of various methods for human segmentation\n",
      "\n",
      "**Main Results:**\n",
      "* The paper presents a comprehensive review of existing methods for semantic segmentation\n",
      "* It highlights the strengths and weaknesses of different architectures and techniques\n",
      "* The importance of statistical analysis and performance evaluation is emphasized\n",
      "* The paper provides a comparative analysis of various methods for human segmentation\n",
      "\n",
      "**Figures & Tables:**\n",
      "* Table comparing the average validation loss, training loss, validation IoU, and training IoU for all encoders and optimizers\n",
      "* Bar plots comparing the average validation loss, training loss, validation IoU, and training IoU for all encoders and optimizers\n",
      "* Graphical representations of trends in segmentation accuracy\n",
      "\n",
      "**Methods:**\n",
      "The paper uses a range of deep learning-based architectures, including U-Net, SegNet, and DeepLab, and explores the use of different optimizers and encoders for improving segmentation accuracy. Statistical analysis and performance evaluation are also discussed.\n",
      "\n",
      "**Citation Notes:**\n",
      "* The paper cites various existing architectures, including U-Net [16], SegNet [20], and DeepLab [11]\n",
      "* It also mentions the use of different optimizers and encoders, such as [8] and [10]\n",
      "* The paper highlights the importance of statistical analysis and performance evaluation, citing [18] and [19]\n",
      "* The paper provides a comprehensive review of existing methods for semantic segmentation, citing [1]-[7] and [12]-[15]\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516d2a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
